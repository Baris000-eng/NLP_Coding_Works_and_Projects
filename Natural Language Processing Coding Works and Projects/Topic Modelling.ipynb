{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01948c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling #\n",
    "\n",
    "# Topic Modelling Overview \n",
    "\n",
    "# Topic Modelling allows for us to efficiently analyze large volumes of text by clustering \n",
    "# the documents into topics.\n",
    "\n",
    "# A large amount of text data is unlabeled, which means we will not be able to apply the \n",
    "# supervised learning approaches to create machine learning models for the data. Because \n",
    "# the supervised machine learning approaches depend on the historical labelled data.\n",
    "\n",
    "# It is up to use to try to discover text labels through the usage of topic modelling.\n",
    "\n",
    "# If we have unlabeled data, then we can attempt to \"discover\" the labels. In the case of \n",
    "# text data, this means attempting to discover clusters of similar documents, grouped \n",
    "# together by topic.\n",
    "\n",
    "# A very important idea to keep in mind here is that we do not know the \"correct topic\" or\n",
    "# the \"right answer\". All we know is that the documents which are clustered together share\n",
    "# similar topic ideas. It is up to the user to determine what these topics represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3def508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Dirichlet Allocation (LDA) for Topic Modelling\n",
    "\n",
    "# * Johann Peter Gustav Lejeune Dirichlet was a German mathematician in the 1800s who \n",
    "# contributed widely to the field of modern mathematics.\n",
    "\n",
    "# There is a probability distribution named after him, \"Dirichlet Distribution\". The \n",
    "# Latent Dirichlet Allocation (LDA) is based on this probability distribution.\n",
    "\n",
    "# In 2003, LDA was first published as a graphical model for topic discovery in \n",
    "# Journal of Machine Learning research.\n",
    "\n",
    "# Assumptions of LDA for Topic Modelling\n",
    "\n",
    "# 1-) Documents with similar topics use similar groups of words\n",
    "# 2-) Latent topics can be found by searching for groups of words which frequently occur together \n",
    "# in documents across the corpus.\n",
    "\n",
    "# - Documents are probability distributions over latent topics.\n",
    "# - Topics themselves are probability distributions over words.\n",
    "\n",
    "# LDA represents documents as mixtures of topics which generate words with certain probabilities.\n",
    "\n",
    "\n",
    "# LDA assumes that the documents are produced in the following fashion: \n",
    "\n",
    "# - Decide on the number of words N the document will have.\n",
    "# - Choose a topic mixture for the document (according to the Dirichlet distribution over a fixed set of K topics)\n",
    "   # * e.g. 55% business, 25% politics, 10% economics 10% trade\n",
    "    \n",
    "# Generate each word in the document by: \n",
    "  # First picking a topic according to the multinomial distribution that is sampled in the previous step \n",
    "  # (55% business, 25% politics, 10% economics, and 10% trade).\n",
    "\n",
    "# Use the topic to generate the word itself (according to the topic's multinomial distribution). For instance,\n",
    "# if we choose the topic named 'economics', we might generate the word 'stocks' with 50% probability, \n",
    "# 'investment' with 35% probability, and so forth.\n",
    "\n",
    "# Assuming this generative model for a collection of documents, LDA then tries to backtrack from the documents \n",
    "# to find a set of topics that are likely to have generated the collection.\n",
    "\n",
    "\n",
    "# We have choosen a fixed number of K topics, and want to use LDA to learn the topic representation of each \n",
    "# document and the words associated to each topic.\n",
    "\n",
    "# We are going to go through each document, and randomly assign each word in the document to one of the K topics.\n",
    "\n",
    "# This random assignment gives us the topic representations of all the documents and word distributions of all \n",
    "# the topics.\n",
    "\n",
    "# We iterate through every word in every document to improve this fixed set of topics.\n",
    "\n",
    "# For every word in every document and for each topic t, we calculate the following: \n",
    "# p(topic t | document d) = the proportion of words in the document d that are currently assigned to topic t.\n",
    "\n",
    "# Reassign w a new topic, where we choose topic t with the below probability: \n",
    "\n",
    "# p(topic t | document d) * p(word w | topic t)\n",
    "# This probability is essentially the probability that the topic t generated word w.\n",
    "\n",
    "# After repeating the previous step for many times, we finally reach an approximately steady state where \n",
    "# the assignments are acceptable.\n",
    "\n",
    "# Ultimately, we have each document being assigned to a topic. We can also search for the words which have \n",
    "# the highest probability of being assigned to a topic.\n",
    "\n",
    "# We end up with an output such as: \n",
    "\n",
    "# Document assigned to the Topic #4\n",
    "# Most common words (highest probability) for Topic #4:\n",
    "# ['cat', 'dog', 'vet', 'birds', 'food', 'home', ...]\n",
    "\n",
    "# Two important notes: \n",
    "# 1-) The user must decide on the amount of topics present in the document.\n",
    "# 2-) The user must interpret what the topics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14893b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Article\n",
      "0      In the Washington of 2016, even when the polic...\n",
      "1        Donald Trump has used Twitter  —   his prefe...\n",
      "2        Donald Trump is unabashedly praising Russian...\n",
      "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
      "4      From photography, illustration and video, to d...\n",
      "...                                                  ...\n",
      "11987  The number of law enforcement officers shot an...\n",
      "11988    Trump is busy these days with victory tours,...\n",
      "11989  It’s always interesting for the Goats and Soda...\n",
      "11990  The election of Donald Trump was a surprise to...\n",
      "11991  Voters in the English city of Sunderland did s...\n",
      "\n",
      "[11992 rows x 1 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Latent Dirichlet Allocation\n",
    "import pandas as pd\n",
    "npr = pd.read_csv('npr.csv')\n",
    "print(npr)\n",
    "print()\n",
    "print(type(npr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22469b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        In the Washington of 2016, even when the polic...\n",
      "1          Donald Trump has used Twitter  —   his prefe...\n",
      "2          Donald Trump is unabashedly praising Russian...\n",
      "3        Updated at 2:50 p. m. ET, Russian President Vl...\n",
      "4        From photography, illustration and video, to d...\n",
      "                               ...                        \n",
      "11987    The number of law enforcement officers shot an...\n",
      "11988      Trump is busy these days with victory tours,...\n",
      "11989    It’s always interesting for the Goats and Soda...\n",
      "11990    The election of Donald Trump was a surprise to...\n",
      "11991    Voters in the English city of Sunderland did s...\n",
      "Name: Article, Length: 11992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aae6dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11992 articles in this dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(npr['Article']))+\" articles in this dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "515fbd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_df=0.95, min_df=0.15, stop_words='english')\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.15, max_df=0.95, stop_words = 'english')\n",
    "print(cv)\n",
    "print(type(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77b874b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 169)\t2\n",
      "  (0, 181)\t3\n",
      "  (0, 83)\t3\n",
      "  (0, 119)\t6\n",
      "  (0, 72)\t3\n",
      "  (0, 88)\t1\n",
      "  (0, 14)\t6\n",
      "  (0, 65)\t3\n",
      "  (0, 44)\t1\n",
      "  (0, 78)\t2\n",
      "  (0, 7)\t1\n",
      "  (0, 179)\t4\n",
      "  (0, 182)\t2\n",
      "  (0, 69)\t2\n",
      "  (0, 180)\t1\n",
      "  (0, 110)\t2\n",
      "  (0, 131)\t4\n",
      "  (0, 155)\t1\n",
      "  (0, 106)\t1\n",
      "  (0, 159)\t19\n",
      "  (0, 124)\t1\n",
      "  (0, 95)\t2\n",
      "  (0, 174)\t1\n",
      "  (0, 160)\t1\n",
      "  (0, 167)\t1\n",
      "  :\t:\n",
      "  (11991, 133)\t1\n",
      "  (11991, 143)\t1\n",
      "  (11991, 134)\t8\n",
      "  (11991, 158)\t1\n",
      "  (11991, 113)\t7\n",
      "  (11991, 162)\t2\n",
      "  (11991, 156)\t1\n",
      "  (11991, 84)\t1\n",
      "  (11991, 13)\t1\n",
      "  (11991, 103)\t1\n",
      "  (11991, 114)\t2\n",
      "  (11991, 58)\t1\n",
      "  (11991, 0)\t1\n",
      "  (11991, 175)\t1\n",
      "  (11991, 59)\t1\n",
      "  (11991, 87)\t4\n",
      "  (11991, 178)\t2\n",
      "  (11991, 32)\t1\n",
      "  (11991, 166)\t1\n",
      "  (11991, 61)\t1\n",
      "  (11991, 23)\t1\n",
      "  (11991, 75)\t1\n",
      "  (11991, 116)\t1\n",
      "  (11991, 4)\t1\n",
      "  (11991, 77)\t2\n"
     ]
    }
   ],
   "source": [
    "document_term_matrix = cv.fit_transform(npr['Article'])\n",
    "print(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a016561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x185 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 535794 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4996feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(n_components=20, random_state=42)\n",
      "<class 'sklearn.decomposition._lda.LatentDirichletAllocation'>\n"
     ]
    }
   ],
   "source": [
    "# Apply Latent Dirichlet Allocation\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# creating an lda instance where the random state is equal to 42 and the number of topics seeked is 20\n",
    "lda = LatentDirichletAllocation(n_components=20, random_state=42)\n",
    "\n",
    "\n",
    "print(lda)\n",
    "print(type(lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa05fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=20, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting lda to the document_term_matrix\n",
    "lda.fit(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f294bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "\n",
      "<class 'list'>\n",
      "\n",
      "000\n",
      "10\n",
      "20\n",
      "able\n",
      "according\n",
      "actually\n",
      "ago\n",
      "america\n",
      "american\n",
      "asked\n",
      "away\n",
      "best\n",
      "better\n",
      "big\n",
      "called\n",
      "came\n",
      "campaign\n",
      "care\n",
      "case\n",
      "center\n",
      "change\n",
      "children\n",
      "city\n",
      "clear\n",
      "come\n",
      "comes\n",
      "country\n",
      "course\n",
      "day\n",
      "days\n",
      "department\n",
      "did\n",
      "didn\n",
      "different\n",
      "director\n",
      "does\n",
      "doesn\n",
      "doing\n",
      "don\n",
      "donald\n",
      "earlier\n",
      "early\n",
      "end\n",
      "especially\n",
      "example\n",
      "fact\n",
      "family\n",
      "far\n",
      "federal\n",
      "feel\n",
      "getting\n",
      "given\n",
      "going\n",
      "good\n",
      "got\n",
      "government\n",
      "great\n",
      "group\n",
      "hard\n",
      "having\n",
      "health\n",
      "help\n",
      "high\n",
      "history\n",
      "home\n",
      "house\n",
      "human\n",
      "idea\n",
      "important\n",
      "including\n",
      "instead\n",
      "isn\n",
      "just\n",
      "kind\n",
      "know\n",
      "known\n",
      "later\n",
      "law\n",
      "left\n",
      "let\n",
      "life\n",
      "like\n",
      "likely\n",
      "little\n",
      "live\n",
      "lives\n",
      "ll\n",
      "local\n",
      "long\n",
      "look\n",
      "looking\n",
      "lot\n",
      "make\n",
      "makes\n",
      "making\n",
      "man\n",
      "means\n",
      "media\n",
      "million\n",
      "money\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barissss/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# grab the vocabulary of words \n",
    "\n",
    "words_vocab = cv.get_feature_names()\n",
    "print(len(words_vocab))\n",
    "print()\n",
    "print(type(words_vocab))\n",
    "print()\n",
    "for i in range(0, 100):\n",
    "    print(words_vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "923cbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(type(words_vocab))\n",
    "\n",
    "import random \n",
    "\n",
    "random_word_id = random.randint(0, 185)\n",
    "print(random_word_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55153a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb663bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bfe5f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.99512296e+02 3.35814296e+02 3.02808998e+02 ... 1.89997033e+03\n",
      "  1.14663701e+01 2.15987452e+02]\n",
      " [7.78239990e+02 2.43059236e+02 1.69066582e+02 ... 1.89701635e+03\n",
      "  3.85539978e-01 3.00232383e+02]\n",
      " [1.19333943e+01 7.78627904e+01 4.98411992e+01 ... 1.65145067e+02\n",
      "  3.10770850e+02 9.96143266e-01]\n",
      " ...\n",
      " [2.23705317e+02 1.51123297e+02 1.04184226e+02 ... 1.43265139e+02\n",
      "  3.45703618e-01 2.44484804e+01]\n",
      " [4.66926713e+02 3.54011773e+02 2.14956168e+02 ... 4.13937845e+02\n",
      "  2.27145484e+01 2.26862642e+01]\n",
      " [6.99069565e-01 1.84012321e+02 6.49793619e+01 ... 7.11155996e+02\n",
      "  1.85826049e+02 1.59077952e+03]]\n",
      "\n",
      "20\n",
      "The type of the topics is: <class 'numpy.ndarray'>\n",
      "The type of the lda.components_ is: <class 'numpy.ndarray'>\n",
      "(20, 185)\n",
      "Total number of rows: 20\n",
      "Total number of columns: 185\n",
      "\n",
      "There are 20 topics seeked and 185 words in the topics data.\n"
     ]
    }
   ],
   "source": [
    "# grab the topics\n",
    "topics = lda.components_\n",
    "print(topics)\n",
    "print()\n",
    "print(len(topics))\n",
    "print(\"The type of the topics is: \"+str(type(topics))+\"\")\n",
    "print(\"The type of the lda.components_ is: \"+str(type(lda.components_))+\"\")\n",
    "\n",
    "topics_shape = topics.shape\n",
    "print(topics_shape)\n",
    "\n",
    "row_num = topics.shape[0]\n",
    "col_num = topics.shape[1]\n",
    "\n",
    "print(\"Total number of rows: \"+str(row_num)+\"\")\n",
    "print(\"Total number of columns: \"+str(col_num)+\"\")\n",
    "print()\n",
    "print(\"There are \"+str(row_num)+\" topics seeked and \"+str(col_num)+\" words in the topics data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bdd148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first topic: [3.99512296e+02 3.35814296e+02 3.02808998e+02 7.04191064e+02\n",
      " 3.01254709e+02 7.51823477e+02 6.37757337e+02 7.76051731e+01\n",
      " 1.51458920e+02 1.86963650e+02 5.33382813e+02 2.91193779e+02\n",
      " 5.77648500e+02 1.09238707e+03 1.02807211e+03 3.59263778e+02\n",
      " 4.56788099e-01 4.40796524e+01 2.66476766e+02 7.25702671e+02\n",
      " 7.82644839e+02 4.58630114e+00 6.06367771e+01 1.76532724e+02\n",
      " 9.44794115e+02 4.41747362e+02 2.60833734e+02 1.59833371e+02\n",
      " 7.70140350e+02 3.84992626e+02 1.67830946e+02 3.68548962e+02\n",
      " 7.07178526e+02 7.83455790e+02 5.50848415e+02 3.96230989e+02\n",
      " 1.01290421e+03 5.84302110e+02 2.26019814e+03 5.00000004e-02\n",
      " 1.08521849e+02 2.25913317e+02 3.88261567e+02 4.17570384e+02\n",
      " 3.68828258e+02 2.21549661e+02 2.52491960e+01 5.30983754e+02\n",
      " 1.05974198e+01 3.86747440e+02 8.81888878e+02 1.21791566e+02\n",
      " 1.66789637e+03 9.73784454e+02 8.77950313e+02 7.60357116e+01\n",
      " 1.68332597e+02 5.84092560e+02 4.87872077e+02 3.83861401e+02\n",
      " 1.06916948e+01 1.04206992e+03 3.69755660e+02 8.72066961e+01\n",
      " 1.99416796e+02 2.52106405e+01 1.89811955e+02 4.86395038e+02\n",
      " 5.10649178e+02 3.81221644e+02 3.20621468e+02 6.30556495e+02\n",
      " 3.50055338e+03 6.99553149e+02 1.39096882e+03 3.21912604e+02\n",
      " 1.99637493e+02 3.64377957e+00 1.84315087e+02 1.69425733e+02\n",
      " 2.21281984e+02 4.41950908e+03 3.21221675e+02 8.28178394e+02\n",
      " 2.40512904e+02 1.46488518e+02 6.59015238e+02 4.39743036e+02\n",
      " 7.30951225e+02 6.98458159e+02 5.97053038e+02 1.57594214e+03\n",
      " 1.66144793e+03 5.13029821e+02 4.80615891e+02 7.34713202e+01\n",
      " 4.14894780e+02 1.11281677e+02 2.51554201e+02 3.00404520e+02\n",
      " 2.33365275e+02 3.82264398e+02 5.35560105e+02 1.79504697e+02\n",
      " 9.66397620e+02 1.71371976e+03 6.51126340e+01 9.79974415e+01\n",
      " 9.98428108e+01 3.34951831e+02 6.47591670e+01 3.74640215e+02\n",
      " 4.09327909e+02 5.09268678e+03 2.68522244e+02 3.66832477e+02\n",
      " 4.83165160e+02 2.78347254e+02 1.12167484e+01 2.00125586e+01\n",
      " 7.06530716e-02 7.66284167e+02 3.73856818e+02 2.17407116e+02\n",
      " 3.98086939e+02 1.83138342e+03 2.91236074e+02 1.26468549e+01\n",
      " 3.27488891e+00 4.87847189e+02 1.04018980e+03 1.42662109e+01\n",
      " 1.55043116e+03 1.19348673e+02 3.55900366e+04 3.97603293e+01\n",
      " 3.74049166e+02 2.08613101e+02 7.76861356e+02 4.39487305e+02\n",
      " 7.47859573e+02 6.19415611e+01 7.71515537e-02 2.99050033e+01\n",
      " 2.66776873e+02 1.19603796e+02 5.57257358e+02 4.45466452e+02\n",
      " 2.09333216e+02 2.49227766e+02 5.63848914e+02 8.15885987e+02\n",
      " 1.49634487e+03 3.69193458e+02 1.49457796e+03 2.84021760e+02\n",
      " 3.10303470e+02 1.23698671e+02 3.50820641e+02 5.00000002e-02\n",
      " 8.17674765e+02 1.58037048e+01 1.50775220e+03 9.29409724e+02\n",
      " 1.03739862e+03 7.62146562e+02 1.07908706e+03 1.30414743e+03\n",
      " 1.93959277e+02 2.21814444e+02 3.56886473e+02 1.40780426e+03\n",
      " 2.38232584e+02 2.59681704e+02 1.37544744e+00 5.12094254e-02\n",
      " 2.15583084e+02 1.25153645e+03 6.56965111e+02 4.59028881e+02\n",
      " 1.55509444e+01 8.51526361e+02 1.89997033e+03 1.14663701e+01\n",
      " 2.15987452e+02]\n"
     ]
    }
   ],
   "source": [
    "single_topic = lda.components_[0]\n",
    "print(\"The first topic: \"+str(single_topic)+\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f86b115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159,  39, 175, 120, 142,  16, 174, 128,  77,  21,  48,  60, 118,\n",
       "       183, 127, 131, 180, 161, 119,  65,  46, 143, 135,  17,  22, 141,\n",
       "       110, 106,  95,  55,   7,  63, 107, 108,  40,  97, 133, 145,  51,\n",
       "       157,  85,   8,  27,  30,  56,  79,  23, 103,  78,   9,  66, 168,\n",
       "        64,  76, 137, 148, 176, 184, 123,  80,  45, 169,  41, 100, 172,\n",
       "        84, 149,  98, 173,  26,  18, 144, 114, 117, 155,  11, 126,  99,\n",
       "         4,   2, 156,  70,  82,  75, 109,   1, 158, 170,  15, 115,  31,\n",
       "        44, 153,  62, 122, 136, 111,  69, 101,  59,  29,  49,  42,  35,\n",
       "       124,   0, 112,  96,  43, 139,  87,  25, 147, 179,  94, 116,  67,\n",
       "       129,  58,  68,  93,  47,  10, 102,  34, 146, 150,  12,  57,  37,\n",
       "        90,  71,   6, 178,  86,  89,  73,   3,  32,  19,  88, 140,   5,\n",
       "       165, 121,  28, 138,  20,  33, 151, 160,  83, 181,  54,  50, 163,\n",
       "        24, 104,  53,  36,  14, 164, 130,  61, 166,  13, 177, 167,  74,\n",
       "       171, 154, 152, 162, 132,  91,  92,  52, 105, 125, 182,  38,  72,\n",
       "        81, 113, 134])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfbffb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159  39 175 120 142  16 174 128  77  21  48  60 118 183 127 131 180 161\n",
      " 119  65  46 143 135  17  22 141 110 106  95  55   7  63 107 108  40  97\n",
      " 133 145  51 157  85   8  27  30  56  79  23 103  78   9  66 168  64  76\n",
      " 137 148 176 184 123  80  45 169  41 100 172  84 149  98 173  26  18 144\n",
      " 114 117 155  11 126  99   4   2 156  70  82  75 109   1 158 170  15 115\n",
      "  31  44 153  62 122 136 111  69 101  59  29  49  42  35 124   0 112  96\n",
      "  43 139  87  25 147 179  94 116  67 129  58  68  93  47  10 102  34 146\n",
      " 150  12  57  37  90  71   6 178  86  89  73   3  32  19  88 140   5 165\n",
      " 121  28 138  20  33 151 160  83 181  54  50 163  24 104  53  36  14 164\n",
      " 130  61 166  13 177 167  74 171 154 152 162 132  91  92  52 105 125 182\n",
      "  38  72  81 113 134]\n"
     ]
    }
   ],
   "source": [
    "# It gets the list of index positions of the high probability words for the first topic, \n",
    "# meaning the topic located at the 0th index.\n",
    "print(single_topic.argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab02dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 92  52 105 125 182  38  72  81 113 134]\n"
     ]
    }
   ],
   "source": [
    "print(single_topic.argsort()[-10:]) # top 10 high-probable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72cdd440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "work\n",
      "want\n",
      "know\n",
      "way\n",
      "time\n",
      "think\n",
      "university\n",
      "say\n",
      "lot\n",
      "make\n",
      "going\n",
      "new\n",
      "really\n",
      "years\n",
      "don\n",
      "just\n",
      "like\n",
      "people\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "# Displaying top 20 high-probable words that can show up in the topic called 'single_topic'\n",
    "\n",
    "top_twenty_words = single_topic.argsort()[-20:]\n",
    "feature_names = cv.get_feature_names()\n",
    "for index in top_twenty_words:\n",
    "    print(feature_names[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2a2b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20 300  11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([20, 300, 11])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e31528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20 300  11]\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(arr)\n",
    "\n",
    "# sorts the values in an ascending order and returns the indices of these values in a sequence\n",
    "# Since 11 is the smallest value in the numpy array called 'arr', its index (2) comes first in the \n",
    "# argsort() call. 20 is greater than 11 and it is the smallest choice that we can take which is\n",
    "# larger than 11. So, the index of '20' (0) takes the second place in the output. Because of the \n",
    "# fact that 300 is the largest value in the numpy array called arr, its index (1) takes the last \n",
    "# index position in the output of argsort() call.\n",
    "\n",
    "# In short, argsort() returns the index positions that will sort the array with which argsort() is called.\n",
    "print(arr.argsort()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74930774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for the topic 0 are: \n",
      "\n",
      "['time', 'think', 'university', 'say', 'lot', 'make', 'going', 'new', 'really', 'years', 'don', 'just', 'like', 'people', 'says']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 1 are: \n",
      "\n",
      "['country', 'people', 'just', 'ago', '000', 'work', 'help', 'time', 'day', 'children', 'life', 'years', 'home', 'family', 'says']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 2 are: \n",
      "\n",
      "['news', 'night', 'going', 'week', 'just', 'support', 'won', 'new', 'states', 'political', 'president', 'said', 'donald', 'campaign', 'trump']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 3 are: \n",
      "\n",
      "['says', 'likely', 'new', 'nearly', 'day', '10', 'years', 'world', 'according', 'number', 'million', '000', 'year', 'people', 'percent']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 4 are: \n",
      "\n",
      "['country', 'week', 'government', 'year', 'years', 'campaign', 'washington', 'white', 'support', 'office', 'political', 'national', 'said', 'house', 'president']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 5 are: \n",
      "\n",
      "['today', 'different', 'early', 'work', 'history', 'make', 'life', 'long', 'just', 'way', 'new', 'years', 'world', 'time', 'like']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 6 are: \n",
      "\n",
      "['public', 'just', 'make', 'new', 'percent', 'campaign', 'according', 'said', '000', 'year', 'states', 'department', 'million', 'money', 'state']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 7 are: \n",
      "\n",
      "['people', 'say', 'new', 'united', 'says', 'use', 'state', 'public', 'said', 'department', 'states', 'case', 'government', 'federal', 'law']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 8 are: \n",
      "\n",
      "['example', 'important', 'new', 'need', 'using', 'likely', 'used', 'work', 'help', 'group', 'human', 'university', 'use', 'research', 'children']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 9 are: \n",
      "\n",
      "['say', 'think', 'want', 'time', 'going', 'did', 'know', 'like', 'asked', 'don', 'didn', 'just', 'people', 'told', 'said']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 10 are: \n",
      "\n",
      "['way', 'lives', 'did', 'man', 'group', 'media', 'american', 'america', 'wrote', 'house', 'like', 'history', 'political', 'people', 'white']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 11 are: \n",
      "\n",
      "['npr', 'government', 'told', 'press', 'week', 'washington', 'new', 'department', 'director', 'office', 'said', 'white', 'house', 'president', 'trump']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 12 are: \n",
      "\n",
      "['including', 'like', 'place', 'week', 'called', 'just', 'local', 'time', 'year', 'public', 'years', 'times', 'york', 'city', 'new']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 13 are: \n",
      "\n",
      "['new', 've', 'national', 'political', 'government', 'make', 'president', 'going', 'world', 'states', 'united', 'people', 'america', 'american', 'country']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 14 are: \n",
      "\n",
      "['say', 'time', 'want', 'way', 'lot', 'things', 've', 'going', 'don', 'really', 'know', 'just', 'think', 'people', 'like']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 15 are: \n",
      "\n",
      "['work', 'make', 'including', 'american', 'support', 'public', 'don', 'told', 'family', 'says', 'said', 'like', 'young', 'group', 'women']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 16 are: \n",
      "\n",
      "['help', 'time', 'years', 'day', 'percent', 'need', 'says', 'like', 'just', 'children', 'year', 'university', 'public', 'high', 'school']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 17 are: \n",
      "\n",
      "['family', 'year', 'don', 'federal', 'news', 'help', 'said', 'percent', 'need', 'law', 'states', 'public', 'people', 'care', 'health']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 18 are: \n",
      "\n",
      "['including', 'time', 'say', 'says', 'press', 'media', 'statement', 'told', 'people', 'according', 'reported', 'news', 'npr', 'reports', 'said']\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "The top 15 words for the topic 19 are: \n",
      "\n",
      "['did', 'new', 'year', 'day', 'world', 'little', 'just', 'time', 'young', 'best', 'night', 'life', 'man', 'like', 'story']\n",
      "\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barissss/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# grab the highest probability words per topic\n",
    "for index, topic in enumerate(topics):\n",
    "    print(\"The top 15 words for the topic \"+str(index)+\" are: \")\n",
    "    print()\n",
    "    top15_words = [cv.get_feature_names()[index] for index in topic.argsort()[-15:]]\n",
    "    print(top15_words)\n",
    "    print()\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d4949f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x185 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 535794 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06166aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "0      In the Washington of 2016, even when the polic...\n",
       "1        Donald Trump has used Twitter  —   his prefe...\n",
       "2        Donald Trump is unabashedly praising Russian...\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4      From photography, illustration and video, to d...\n",
       "...                                                  ...\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s...\n",
       "\n",
       "[11992 rows x 1 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c56087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.75939856e-04 3.75939857e-04 2.58978596e-01 ... 3.75939854e-04\n",
      "  3.75939863e-04 8.41715411e-02]\n",
      " [6.02409649e-04 6.02409652e-04 6.43703216e-01 ... 6.02409645e-04\n",
      "  1.20906457e-01 6.02409656e-04]\n",
      " [4.31034489e-04 4.31034489e-04 5.34020442e-01 ... 4.31034486e-04\n",
      "  2.93180840e-02 4.31034491e-04]\n",
      " ...\n",
      " [6.84931519e-04 7.69371022e-02 6.84931516e-04 ... 7.94475603e-02\n",
      "  6.84931520e-04 3.20664221e-01]\n",
      " [7.93650810e-04 7.93650808e-04 1.92791430e-01 ... 7.93650806e-04\n",
      "  7.93650805e-04 7.97601603e-02]\n",
      " [2.27106258e-01 8.95326899e-02 1.69197313e-02 ... 4.76190483e-04\n",
      "  4.76190488e-04 4.76190485e-04]]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11992 20\n",
      "There are 11992 articles presented and 20 topics seeked in the data frame.\n"
     ]
    }
   ],
   "source": [
    "topic_results = lda.transform(document_term_matrix)\n",
    "print(topic_results)\n",
    "print(type(topic_results))\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(topic_results.shape[0], topic_results.shape[1])\n",
    "print(\"There are \"+str(topic_results.shape[0])+\" articles presented and \"+str(topic_results.shape[1])+\" topics seeked in the data frame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "31ab385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00037594 0.00037594 0.2589786  0.00037594 0.18400657 0.23144787\n",
      " 0.00037594 0.00037594 0.01492258 0.00037594 0.00037594 0.20850575\n",
      " 0.01307987 0.00037594 0.00037594 0.00037594 0.00037594 0.00037594\n",
      " 0.00037594 0.08417154]\n"
     ]
    }
   ],
   "source": [
    "# probabilities of the first article belonging to a particular topic for each topic in the list of topics\n",
    "print(topic_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ecd70752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0004, 0.0004, 0.259 , 0.0004, 0.184 , 0.2314, 0.0004, 0.0004,\n",
       "       0.0149, 0.0004, 0.0004, 0.2085, 0.0131, 0.0004, 0.0004, 0.0004,\n",
       "       0.0004, 0.0004, 0.0004, 0.0842])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The below call will round every element in the first element of the array called topic\n",
    "topic_results[0].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ed7c292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.259, 0.   , 0.184, 0.231, 0.   , 0.   , 0.015,\n",
       "       0.   , 0.   , 0.209, 0.013, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.084])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff4f3c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].argmax() # It returns the index position of the highest probability topic for the first article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "36edea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.75939856e-04 3.75939857e-04 2.58978596e-01 ... 3.75939854e-04\n",
      "  3.75939863e-04 8.41715411e-02]\n",
      " [6.02409649e-04 6.02409652e-04 6.43703216e-01 ... 6.02409645e-04\n",
      "  1.20906457e-01 6.02409656e-04]\n",
      " [4.31034489e-04 4.31034489e-04 5.34020442e-01 ... 4.31034486e-04\n",
      "  2.93180840e-02 4.31034491e-04]\n",
      " ...\n",
      " [6.84931519e-04 7.69371022e-02 6.84931516e-04 ... 7.94475603e-02\n",
      "  6.84931520e-04 3.20664221e-01]\n",
      " [7.93650810e-04 7.93650808e-04 1.92791430e-01 ... 7.93650806e-04\n",
      "  7.93650805e-04 7.97601603e-02]\n",
      " [2.27106258e-01 8.95326899e-02 1.69197313e-02 ... 4.76190483e-04\n",
      "  4.76190488e-04 4.76190485e-04]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                 Article  Topic\n",
      "0      In the Washington of 2016, even when the polic...      2\n",
      "1        Donald Trump has used Twitter  —   his prefe...      2\n",
      "2        Donald Trump is unabashedly praising Russian...      2\n",
      "3      Updated at 2:50 p. m. ET, Russian President Vl...     11\n",
      "4      From photography, illustration and video, to d...      3\n",
      "...                                                  ...    ...\n",
      "11987  The number of law enforcement officers shot an...      3\n",
      "11988    Trump is busy these days with victory tours,...      5\n",
      "11989  It’s always interesting for the Goats and Soda...     19\n",
      "11990  The election of Donald Trump was a surprise to...     14\n",
      "11991  Voters in the English city of Sunderland did s...      0\n",
      "\n",
      "[11992 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(topic_results)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "npr['Topic'] = topic_results.argmax(axis=1)\n",
    "print(npr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d243dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Washington of 2016, even when the policy can be bipartisan, the politics cannot. And in that sense, this year shows little sign of ending on Dec. 31. When President Obama moved to sanction Russia over its alleged interference in the U. S. election just concluded, some Republicans who had long called for similar or more severe measures could scarcely bring themselves to approve. House Speaker Paul Ryan called the Obama measures ”appropriate” but also ”overdue” and ”a prime example of this administration’s ineffective foreign policy that has left America weaker in the eyes of the world.” Other GOP leaders sounded much the same theme. ”[We have] been urging President Obama for years to take strong action to deter Russia’s worldwide aggression, including its   operations,” wrote Rep. Devin Nunes,  . chairman of the House Intelligence Committee. ”Now with just a few weeks left in office, the president has suddenly decided that some stronger measures are indeed warranted.” Appearing on CNN, frequent Obama critic Trent Franks,  . called for ”much tougher” actions and said three times that Obama had ”finally found his tongue.” Meanwhile, at    and on Fox News, various spokesmen for   Trump said Obama’s real target was not the Russians at all but the man poised to take over the White House in less than three weeks. They spoke of Obama trying to ”tie Trump’s hands” or ”box him in,” meaning the   would be forced either to keep the sanctions or be at odds with Republicans who want to be tougher still on Moscow. Throughout 2016, Trump has repeatedly called not for sanctions but for closer ties with Russia, including cooperation in the fight against ISIS. Russia has battled ISIS in Syria on behalf of that country’s embattled dictator, Bashar Assad, bombing the besieged   city of Aleppo that fell to Assad’s forces this week. During the campaign, Trump even urged Russia to ”find” missing emails from the private server of his opponent, Hillary Clinton. He has exchanged public encomiums with Russian President Vladimir Putin on several occasions and added his doubts about the current U. S. levels of support for NATO  —   Putin’s longtime nemesis. There have also been suggestions that Trump’s extensive business dealings with various Russians are the reason he refuses to release his tax returns. All those issues have been disquieting to some Republicans for many months. Sens. John McCain,  . and Lindsay Graham,  . C. prominent senior members of the Armed Services Committee, have accepted the assessment of 17 U. S. intelligence agencies regarding the role of Russia in the hacking of various Democratic committees last year. That includes the FBI and CIA consensus that the Russian goal was not just to discredit American democracy but to defeat Clinton and elect Trump. They say the great majority of their Senate colleagues agree with them, and McCain has slated an Armed Services hearing on cyberthreats for Jan. 5. But the politicizing of the Russian actions  —   the idea that they helped Trump win  —   has also made the issue difficult for Republican leaders. It has allowed Trump supporters to push back on the intelligence agencies and say the entire issue is designed to undermine Trump’s legitimacy. Senate Majority Leader Mitch McConnell has so far resisted calls for a select committee to look into the Russian interference in the 2016 campaign. He has said it is enough for Sen. Richard Burr,  . C. to look into it as chairman of the Senate Intelligence Committee. Typically, Republican leaders and spokesmen say there is no evidence that the actual voting or tallying on Nov. 8 was compromised, and that is true. But it is also a red herring, as interference in those functions has not been alleged and is not the focus of the U. S. intelligence agencies’ concern. For his part, Trump has shown little interest in delving into what happened. He has cast doubt on the U. S. intelligence reports to date and suggested ”no one really knows what happened.” He also has suggested that computers make it very difficult to know who is using them. This week, Trump said it was time to ”get on with our lives and do more important things.” However, at week’s end he did agree to have an intelligence briefing on the subject next week. The   has not wanted the daily intelligence briefings available to him in recent weeks, preferring that they be given to the men he has chosen as his vice president (Mike Pence) and national security adviser (Mike Flynn) with Trump taking them only occasionally. The irony of this controversy arising at the eleventh hour of the Obama presidency can scarcely be overstated, and it defines the dilemma facing both the outgoing president and the incoming party in control. Obama appears to have been reluctant to retaliate against the Russian hacking before the election for fear of seeming to interfere with the election himself. The Republicans, meanwhile, have for years called for greater confrontation with the Russians, with Obama usually resisting. Obama did join with NATO in punishing the Russians with economic sanctions over the annexation of Crimea. Those sanctions may have been painful, coming as they did alongside falling prices for oil  —   the commodity that keeps the Russian economy afloat. On other occasions, despite Russian provocations through surrogates in Syria and elsewhere, Obama did not make overt moves to force Russia’s hand. That includes occasions when Russia was believed to be hacking critical computer systems in neighboring Ukraine, Estonia and Poland. But this week, following a chorus of confirmation from the U. S. intelligence community regarding the Russian role in computer hacking in the political campaign, Obama acted. He imposed a set of mostly diplomatic actions such as sanctioning some Russian officials, closing two diplomatic compounds and expelling 35 Russian diplomats. There may have been more damaging measures taken covertly, and some Russophobes in Washington held out hope for that. But the visible portion of the program scarcely amounted to major retribution. And Putin saw fit to diminish the Obama sanctions further by declining to respond. Although his government has steadfastly denied any interference in the U. S. election, Putin rejected his own foreign minister’s recommended package of    responses. (He even sent an invitation for U. S. diplomats to send their children to a holiday party in Moscow.) That allowed Putin to appear for the moment to be ”the bigger man,” even as he spurned Obama and kept up what has looked like a public bromance with Trump, who tweeted: ”Great move on delay (by V. Putin)   I always knew he was very smart!” At the moment it may seem that the overall Russia question amounts to the first crisis facing the Trump presidency. Whether forced by this campaign interference issue or not, Trump must grasp the nettle of a relationship Mitt Romney once called the greatest threat to U. S. security in the world. To be sure, Trump needs to dispel doubts about his ability to stand up to Putin, who has bullied and cajoled his way to center stage in recent world affairs. But Trump also seems determined to turn the page on past U. S. commitments, from free trade philosophy to funding of NATO and the United Nations. And if his Twitter account is any guide, Trump shows little concern about the conundrum others perceive to be facing him. Above all, Trump has shown himself determined to play by his own rules. A year ago, many were confident that would not work for him in the world of presidential politics. We are about to find out whether it works for him in the Oval Office.\n"
     ]
    }
   ],
   "source": [
    "print(npr['Article'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "51e2d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.75939856e-04 3.75939857e-04 2.58978596e-01 ... 3.75939854e-04\n",
      "  3.75939863e-04 8.41715411e-02]\n",
      " [6.02409649e-04 6.02409652e-04 6.43703216e-01 ... 6.02409645e-04\n",
      "  1.20906457e-01 6.02409656e-04]\n",
      " [4.31034489e-04 4.31034489e-04 5.34020442e-01 ... 4.31034486e-04\n",
      "  2.93180840e-02 4.31034491e-04]\n",
      " ...\n",
      " [6.84931519e-04 7.69371022e-02 6.84931516e-04 ... 7.94475603e-02\n",
      "  6.84931520e-04 3.20664221e-01]\n",
      " [7.93650810e-04 7.93650808e-04 1.92791430e-01 ... 7.93650806e-04\n",
      "  7.93650805e-04 7.97601603e-02]\n",
      " [2.27106258e-01 8.95326899e-02 1.69197313e-02 ... 4.76190483e-04\n",
      "  4.76190488e-04 4.76190485e-04]]\n",
      "\n",
      "\n",
      "[10451   542  4617  3396  5991 11740  6774 10273  4741   855  8589   465\n",
      "  6896  1039  4945  1655  4666  2954 10615  6730]\n",
      "[ 2  2  2 ... 19 14  0]\n",
      "20\n",
      "11992\n"
     ]
    }
   ],
   "source": [
    "print(topic_results)\n",
    "print()\n",
    "print()\n",
    "print(topic_results.argmax(axis=0)) # columnwise list of indices each of which correspond to the maxium value in the column\n",
    "print(topic_results.argmax(axis=1)) # rowwise list of indices each of which correspond to the maximum value in the row\n",
    "\n",
    "\n",
    "# axis = 0 ======> columnwise\n",
    "# axis = 1 ======> rowwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9944a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
