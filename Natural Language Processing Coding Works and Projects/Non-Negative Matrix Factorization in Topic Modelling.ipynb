{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37974a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Negative Matrix Factorization\n",
    "\n",
    "# Non-Negative Matrix factorization is an unsupervised learning algorithm that simultaneously \n",
    "# performs dimensionality reduction and clustering. \n",
    "\n",
    "# We can use this technique in conjunction with TF-IDF to model topics across documents.\n",
    "\n",
    "# We are given a non-negative matrix A, find k-dimension approximation in terms of the \n",
    "# non-negative factors W and H.\n",
    "\n",
    "\n",
    "# Basis Vectors ==> W \n",
    "# Coefficient Matrix ==> H\n",
    "\n",
    "# n * m (data matrix, rows = features, cols = objects) ===> n * k (W, Basis Vectors, rows = features)  k * m (H, Coefficient Matrix, cols = objects)\n",
    "# Note: W >= 0 and H >= 0\n",
    "\n",
    "# Approximate each object (column of A) by a linear combination of k reduced dimensions or \"basis vectors\" in W.\n",
    "\n",
    "# Each basis vector can be interpreted as a cluster. The memberships of objects in these clusters are encoded by H.\n",
    "\n",
    "\n",
    "# Input: Non-negative data matrix (A), number of basis vectors (k), and initial values for \n",
    "# the factors W and H (e.g. random matrices). In topic modelling, The 'k' is the number of \n",
    "# topics we choose. Here, the 'A' is the TF-IDF for the words across all the documents.\n",
    "\n",
    "# Objective function: Some measure of reconstruction error between A and the approximation WH.\n",
    "\n",
    "# Expectation-maximization optimization to refine W and H in order to minimize the objective function.\n",
    "# Common approach is to iterate between two multiplicative update rules until convergence.\n",
    "\n",
    "# Steps: \n",
    "\n",
    "# 1-) Construct a vector space model for the documents (after stopword filtering), which results in a \n",
    "# term document matrix A.\n",
    "\n",
    "# 2-) Apply TF-IDF term weight normalization to A.\n",
    "\n",
    "# 3-) Normalize TF-IDF vectors to unit length.\n",
    "\n",
    "# 4-) Initialize the factors using non-negative double singular value decomposition (NNDSVD) on A.\n",
    "\n",
    "# 5-) Apply a projected gradient non-negative matrix factorization to A.\n",
    "\n",
    "# * Basis Vectors: The topics (clusters) in the data.\n",
    "# * Coefficient Matrix: The membership weights for documents relative to each topic (cluster).\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# * Create a document term matrix with TF-IDF vectorization.\n",
    "# * Resulting W and H.\n",
    "# Basis vectors W = Topics (Clusters)\n",
    "# Coefficients H = Memberships for documents\n",
    "\n",
    "\n",
    "# Important Notes: \n",
    "# Just like LDA, we will need to select the number of expected topics beforehand (the value of k)!\n",
    "# Moreover, just like LDA, we will have to interpret the topics based on the coefficient values\n",
    "# of the words per topic.\n",
    "# Coefficient value is not a probability value like the LDA gives us.\n",
    "\n",
    "\n",
    "\"\"\"Comparison between Latent Dirichlet allocation (LDA) and Non-negative Matrix Factorization (NMF) –\n",
    "\n",
    "Latent Dirichlet allocation (LDA)\n",
    "\n",
    "* Assumes each document has multiple topics.\n",
    "* Works best with longer texts such as full articles, essays, and books.\n",
    "* Evolves as you process new documents with the same model.\n",
    "* Results are not deterministic, meaning you might get different results each time for the same data set.\n",
    "\n",
    "Non-negative Matrix Factorization(NMF)\n",
    "\n",
    "* Calculates how well each document fits each topic, rather than assuming a document has multiple topics.\n",
    "* Usually faster than LDA.\n",
    "* Works best with shorter texts such as tweets or titles.\n",
    "* Results are almost deterministic, having more consistency when running the same data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080bcc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Article\n",
      "0      In the Washington of 2016, even when the polic...\n",
      "1        Donald Trump has used Twitter  —   his prefe...\n",
      "2        Donald Trump is unabashedly praising Russian...\n",
      "3      Updated at 2:50 p. m. ET, Russian President Vl...\n",
      "4      From photography, illustration and video, to d...\n",
      "...                                                  ...\n",
      "11987  The number of law enforcement officers shot an...\n",
      "11988    Trump is busy these days with victory tours,...\n",
      "11989  It’s always interesting for the Goats and Soda...\n",
      "11990  The election of Donald Trump was a surprise to...\n",
      "11991  Voters in the English city of Sunderland did s...\n",
      "\n",
      "[11992 rows x 1 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "npr = pd.read_csv('npr.csv')\n",
    "print(npr)\n",
    "print()\n",
    "print(type(npr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f690647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07042e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article\n",
       "11987  The number of law enforcement officers shot an...\n",
       "11988    Trump is busy these days with victory tours,...\n",
       "11989  It’s always interesting for the Goats and Soda...\n",
       "11990  The election of Donald Trump was a surprise to...\n",
       "11991  Voters in the English city of Sunderland did s..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfcab862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article\n",
      "0  In the Washington of 2016, even when the polic...\n",
      "1    Donald Trump has used Twitter  —   his prefe...\n",
      "2    Donald Trump is unabashedly praising Russian...\n",
      "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
      "4  From photography, illustration and video, to d...\n",
      "\n",
      "\n",
      "                                                 Article\n",
      "11987  The number of law enforcement officers shot an...\n",
      "11988    Trump is busy these days with victory tours,...\n",
      "11989  It’s always interesting for the Goats and Soda...\n",
      "11990  The election of Donald Trump was a surprise to...\n",
      "11991  Voters in the English city of Sunderland did s...\n"
     ]
    }
   ],
   "source": [
    "print(npr.head())\n",
    "print()\n",
    "print()\n",
    "print(npr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40a864a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(max_df=0.9, min_df=2, stop_words='english')\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf = TfidfVectorizer(max_df = 0.90, min_df = 2, stop_words = 'english')\n",
    "print(tfidf)\n",
    "print(type(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca9e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 35089)\t0.03226897967994957\n",
      "  (0, 54092)\t0.020091155964863487\n",
      "  (0, 38081)\t0.01848530736819011\n",
      "  (0, 54067)\t0.012397163630307462\n",
      "  (0, 10755)\t0.02787343599042425\n",
      "  (0, 2084)\t0.015039386128760875\n",
      "  (0, 42314)\t0.022036401840046918\n",
      "  (0, 37132)\t0.019410859475366766\n",
      "  (0, 36306)\t0.03708208498289024\n",
      "  (0, 11215)\t0.04403771437574997\n",
      "  (0, 21789)\t0.02878450387905149\n",
      "  (0, 1489)\t0.023797160985101373\n",
      "  (0, 50697)\t0.019446980637479037\n",
      "  (0, 33048)\t0.024542771720625026\n",
      "  (0, 51402)\t0.016746597091717476\n",
      "  (0, 19989)\t0.02443930384385255\n",
      "  (0, 36685)\t0.030973769110011082\n",
      "  (0, 49906)\t0.02337784417528088\n",
      "  (0, 19711)\t0.019932202578472266\n",
      "  (0, 10363)\t0.03610629520801115\n",
      "  (0, 35891)\t0.015092411075280365\n",
      "  (0, 35436)\t0.024429052861450844\n",
      "  (0, 50587)\t0.019150868499058813\n",
      "  (0, 13837)\t0.053973383521678145\n",
      "  (0, 1932)\t0.027002284256125594\n",
      "  :\t:\n",
      "  (11991, 24722)\t0.01644172551896015\n",
      "  (11991, 30961)\t0.013423780587151574\n",
      "  (11991, 39886)\t0.014046569134225128\n",
      "  (11991, 7572)\t0.02747146498745652\n",
      "  (11991, 47772)\t0.024621351721648654\n",
      "  (11991, 38788)\t0.0105244804942528\n",
      "  (11991, 38259)\t0.015643826957449602\n",
      "  (11991, 9511)\t0.048394635963148296\n",
      "  (11991, 11657)\t0.01963978982339237\n",
      "  (11991, 53014)\t0.009862718553798772\n",
      "  (11991, 50466)\t0.01184247409004277\n",
      "  (11991, 53582)\t0.04623269406439066\n",
      "  (11991, 50426)\t0.01120171325726109\n",
      "  (11991, 42561)\t0.03509442034906929\n",
      "  (11991, 53325)\t0.014329342052327554\n",
      "  (11991, 10366)\t0.01595826977057714\n",
      "  (11991, 54412)\t0.007454565657515723\n",
      "  (11991, 19398)\t0.0160346662215466\n",
      "  (11991, 7061)\t0.014521388980633362\n",
      "  (11991, 29070)\t0.010431668949988631\n",
      "  (11991, 26752)\t0.006719650950072229\n",
      "  (11991, 16123)\t0.02841730210985626\n",
      "  (11991, 32459)\t0.016191347350104537\n",
      "  (11991, 54403)\t0.008530202072840548\n",
      "  (11991, 37411)\t0.016271721758987952\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "document_term_matrix = tfidf.fit_transform(npr['Article'])\n",
    "print(document_term_matrix)\n",
    "print(type(document_term_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d377a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae51b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barissss/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=10, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Non-Negative Matrix Factorization \n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "nmf_model = NMF(n_components = 10, random_state = 42)\n",
    "nmf_model.fit(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84727740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54777\n",
      "There are 54777 unique terms or words in the corpus used to create the TF-IDF representation.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "00\n",
      "000\n",
      "00000\n",
      "000s\n",
      "000th\n",
      "002\n",
      "004\n",
      "007\n",
      "009\n",
      "00s\n",
      "01\n",
      "011\n",
      "012\n",
      "015\n",
      "02\n",
      "021\n",
      "024\n",
      "029\n",
      "03\n",
      "032\n",
      "033\n",
      "04\n",
      "042\n",
      "05\n",
      "050\n",
      "054\n",
      "058\n",
      "06\n",
      "060\n",
      "062\n",
      "064\n",
      "065\n",
      "068\n",
      "07\n",
      "075\n",
      "08\n",
      "080\n",
      "088\n",
      "09\n",
      "094\n",
      "098\n",
      "0_hellofriend\n",
      "10\n",
      "100\n",
      "1000\n",
      "100th\n",
      "101\n",
      "101st\n",
      "102\n",
      "103\n",
      "104\n",
      "1040\n",
      "105\n",
      "105th\n",
      "106\n",
      "1066\n",
      "107\n",
      "1070\n",
      "108\n",
      "109\n",
      "10k\n",
      "10s\n",
      "10th\n",
      "11\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "113th\n",
      "114\n",
      "114th\n",
      "115\n",
      "115th\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "11th\n",
      "12\n",
      "120\n",
      "1200\n",
      "121\n",
      "122\n",
      "123\n",
      "1234\n",
      "124\n",
      "125\n",
      "125th\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "12th\n",
      "13\n",
      "130\n",
      "1300\n",
      "1300s\n",
      "131\n",
      "131st\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "13th\n",
      "14\n",
      "140\n",
      "1400s\n",
      "141\n",
      "142\n",
      "143\n",
      "143rd\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "1492\n",
      "1493\n",
      "14th\n",
      "15\n",
      "150\n",
      "1500\n",
      "1500s\n",
      "150th\n",
      "151\n",
      "1517\n",
      "152\n",
      "1523\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "15girls\n",
      "15th\n",
      "16\n",
      "160\n",
      "1600\n",
      "1600s\n",
      "161\n",
      "1616\n",
      "162\n",
      "1623\n",
      "163\n",
      "1631\n",
      "164\n",
      "165\n",
      "166\n",
      "1662\n",
      "1669\n",
      "167\n",
      "168\n",
      "169\n",
      "16mm\n",
      "16th\n",
      "17\n",
      "170\n",
      "1700s\n",
      "171\n",
      "1713\n",
      "172\n",
      "173\n",
      "1734\n",
      "174\n",
      "1747\n",
      "175\n",
      "176\n",
      "1761\n",
      "1762\n",
      "1766\n",
      "177\n",
      "1770\n",
      "1770s\n",
      "1774\n",
      "1776\n",
      "178\n",
      "1780s\n",
      "1783\n",
      "1784\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "179\n",
      "1790\n",
      "1790s\n",
      "1791\n",
      "1793\n",
      "1796\n",
      "17th\n",
      "18\n",
      "180\n",
      "1800\n",
      "1800s\n",
      "1801\n",
      "1804\n",
      "1808\n",
      "181\n",
      "1810\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "182\n",
      "1820\n",
      "1820s\n",
      "1822\n",
      "1824\n",
      "1825\n",
      "1828\n",
      "1829\n",
      "183\n",
      "1830s\n",
      "1833\n",
      "1835\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "184\n",
      "1840\n",
      "1840s\n",
      "1841\n",
      "1842\n",
      "1845\n",
      "1846\n",
      "1848\n",
      "1849\n",
      "185\n",
      "1850\n",
      "1850s\n",
      "1851\n",
      "1852\n",
      "1854\n",
      "1855\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "186\n",
      "1860\n",
      "1860s\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "187\n",
      "1870\n",
      "1870s\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1879\n",
      "188\n",
      "1880\n",
      "1880s\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1888\n",
      "1889\n",
      "189\n",
      "1890\n",
      "1890s\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "18th\n",
      "19\n",
      "190\n",
      "1900\n",
      "1900s\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "191\n",
      "1910\n",
      "1910s\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "192\n",
      "1920\n",
      "1920s\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "193\n",
      "1930\n",
      "1930s\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "194\n",
      "1940\n",
      "1940s\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "195\n",
      "1950\n",
      "1950s\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "196\n",
      "1960\n",
      "1960s\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "197\n",
      "1970\n",
      "1970s\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "198\n",
      "1980\n",
      "1980s\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "199\n",
      "1990\n",
      "1990s\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "19th\n",
      "1s\n",
      "1st\n",
      "20\n",
      "200\n",
      "2000\n",
      "2000s\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "200th\n",
      "201\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "202\n",
      "2020\n",
      "2020s\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2029\n",
      "203\n",
      "2030\n",
      "2030s\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "204\n",
      "2040\n",
      "2044\n",
      "205\n",
      "2050\n",
      "2052\n",
      "206\n",
      "2060\n",
      "207\n",
      "208\n",
      "209\n",
      "20k\n",
      "20s\n",
      "20th\n",
      "21\n",
      "210\n",
      "2100\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "21st\n",
      "22\n",
      "220\n",
      "2205\n",
      "221\n",
      "222\n",
      "223\n",
      "2231\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "2270\n",
      "228\n",
      "229\n",
      "22nd\n",
      "23\n",
      "230\n",
      "231\n",
      "232\n",
      "232nd\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "23andme\n",
      "23rd\n",
      "24\n",
      "240\n",
      "2400\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "25\n",
      "250\n",
      "250th\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "25th\n",
      "26\n",
      "260\n",
      "2600\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "26th\n",
      "27\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "27th\n",
      "28\n",
      "280\n",
      "2800\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "28th\n",
      "29\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "29th\n",
      "2d\n",
      "2nd\n",
      "30\n",
      "300\n",
      "3000\n",
      "301\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "30pm\n",
      "30s\n",
      "30th\n",
      "31\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "31st\n",
      "32\n",
      "320\n",
      "321\n",
      "323\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "32nd\n",
      "33\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "33rd\n",
      "34\n",
      "340\n",
      "341\n",
      "3411\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "349\n",
      "34th\n",
      "35\n",
      "350\n",
      "351\n",
      "352\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "35th\n",
      "36\n",
      "360\n",
      "361\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "36th\n",
      "37\n",
      "370\n",
      "371\n",
      "372\n",
      "374\n",
      "375\n",
      "376\n",
      "37th\n",
      "38\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "38th\n",
      "39\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "3d\n",
      "3ds\n",
      "3g\n",
      "3rd\n",
      "3s\n",
      "40\n",
      "400\n",
      "400th\n",
      "401\n",
      "402\n",
      "403\n",
      "405\n",
      "406\n",
      "408\n",
      "409\n",
      "40s\n",
      "40th\n",
      "41\n",
      "410\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "418\n",
      "42\n",
      "420\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "42nd\n",
      "43\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "437\n",
      "438\n",
      "439\n",
      "43rd\n",
      "44\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "445\n",
      "446\n",
      "447\n",
      "449\n",
      "44th\n",
      "45\n",
      "450\n",
      "454\n",
      "455\n",
      "458\n",
      "45s\n",
      "45th\n",
      "46\n",
      "460\n",
      "461\n",
      "463\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "46th\n",
      "47\n",
      "470\n",
      "472\n",
      "475\n",
      "476\n",
      "477\n",
      "479\n",
      "47th\n",
      "48\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "485\n",
      "486\n",
      "488\n",
      "489\n",
      "49\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "495\n",
      "496\n",
      "499\n",
      "49ers\n",
      "49th\n",
      "4ever\n",
      "4g\n",
      "4runner\n",
      "4s\n",
      "4th\n",
      "4x100\n",
      "4x200\n",
      "50\n",
      "500\n",
      "5000\n",
      "500th\n",
      "501\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "50s\n",
      "50th\n",
      "51\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "516\n",
      "517\n",
      "51st\n",
      "52\n",
      "520\n",
      "521\n",
      "522\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "529\n",
      "53\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "537\n",
      "538\n",
      "539\n",
      "54\n",
      "540\n",
      "541\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "549\n",
      "55\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "55th\n",
      "56\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "565\n",
      "567\n",
      "568\n",
      "57\n",
      "570\n",
      "573\n",
      "577\n",
      "579\n",
      "57th\n",
      "58\n",
      "580\n",
      "582\n",
      "584\n",
      "585\n",
      "587\n",
      "589\n",
      "58th\n",
      "59\n",
      "590\n",
      "591\n",
      "595\n",
      "596\n",
      "597\n",
      "599\n",
      "59th\n",
      "5c\n",
      "5dollarchallenge\n",
      "5s\n",
      "5th\n",
      "60\n",
      "600\n",
      "6000\n",
      "602\n",
      "604\n",
      "607\n",
      "609\n",
      "60s\n",
      "60th\n",
      "61\n",
      "610\n",
      "611\n",
      "614\n",
      "616\n",
      "617\n",
      "618\n",
      "62\n",
      "620\n",
      "6200\n",
      "622\n",
      "6221\n",
      "625\n",
      "62nd\n",
      "63\n",
      "630\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "639\n",
      "64\n",
      "640\n",
      "644\n",
      "645\n",
      "648\n",
      "65\n",
      "650\n",
      "653\n",
      "654\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "65th\n",
      "66\n",
      "660\n",
      "662\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "67\n",
      "670\n",
      "672\n",
      "673\n",
      "675\n",
      "676\n",
      "67p\n",
      "67th\n",
      "68\n",
      "680\n",
      "682\n",
      "683\n",
      "686\n",
      "687\n",
      "688\n",
      "68th\n",
      "69\n",
      "690\n",
      "691\n",
      "693\n",
      "695\n",
      "696\n",
      "697\n",
      "699\n",
      "69th\n",
      "6m\n",
      "6th\n",
      "70\n",
      "700\n",
      "701\n",
      "702\n",
      "704\n",
      "706\n",
      "709\n",
      "70s\n",
      "70th\n",
      "71\n",
      "710\n",
      "712\n",
      "713\n",
      "715\n",
      "717\n",
      "71st\n",
      "72\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "# As you can see below, the length of the 'feature_names' array is 54777. This means that there are 54777 unique \n",
    "# terms or words in the corpus or collection of documents which are used to create the TF-IDF representation. \n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "print(len(feature_names))\n",
    "\n",
    "print(f\"There are {len(feature_names)} unique terms or words in the corpus used to create the TF-IDF representation.\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "for j in range(0, 1000):\n",
    "    print(feature_names[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c574ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 25 words for topic#0: \n",
      "\n",
      "['lot', 'help', 'time', 'use', 'scientists', 'don', 'make', 'companies', 'work', 'research', 'year', 'university', 'workers', '000', 'years', 'just', 'company', 'study', 'new', 'percent', 'like', 'water', 'food', 'people', 'says']\n",
      "\n",
      "The top 25 words for topic#1: \n",
      "\n",
      "['republicans', 'washington', 'media', 'party', 'office', 'nominee', 'business', 'speech', 'tax', 'news', 'administration', 'cruz', 'election', 'pence', 'gop', 'presidential', 'obama', 'house', 'white', 'republican', 'donald', 'campaign', 'said', 'president', 'trump']\n",
      "\n",
      "The top 25 words for topic#2: \n",
      "\n",
      "['costs', 'services', 'premiums', 'plans', 'said', 'medical', 'insurers', 'house', 'aca', 'percent', 'patients', 'repeal', 'law', 'act', 'republicans', 'tax', 'people', 'plan', 'affordable', 'obamacare', 'coverage', 'medicaid', 'insurance', 'care', 'health']\n",
      "\n",
      "The top 25 words for topic#3: \n",
      "\n",
      "['islamic', 'iraqi', 'civilians', 'reports', 'security', 'mosul', 'president', 'government', 'attack', 'turkey', 'assad', 'iran', 'iraq', 'north', 'china', 'aleppo', 'war', 'korea', 'said', 'forces', 'russia', 'military', 'syrian', 'syria', 'isis']\n",
      "\n",
      "The top 25 words for topic#4: \n",
      "\n",
      "['convention', 'race', 'presidential', 'polls', 'bernie', 'said', 'candidate', 'republican', 'win', 'candidates', 'cruz', 'election', 'primary', 'democrats', 'percent', 'party', 'vote', 'state', 'delegates', 'democratic', 'hillary', 'campaign', 'voters', 'sanders', 'clinton']\n",
      "\n",
      "The top 25 words for topic#5: \n",
      "\n",
      "['band', 'story', 'going', 'black', 'film', 'kind', 'songs', 'things', 'don', 've', 'book', 'love', 'women', 'way', 'time', 'life', 'album', 'song', 'people', 'really', 'know', 'think', 'just', 'like', 'music']\n",
      "\n",
      "The top 25 words for topic#6: \n",
      "\n",
      "['classroom', 'district', 'class', 'public', 'percent', 'university', 'learning', 'colleges', 'says', 'state', 'program', 'child', 'teacher', 'high', 'devos', 'parents', 'children', 'college', 'kids', 'teachers', 'student', 'education', 'schools', 'school', 'students']\n",
      "\n",
      "The top 25 words for topic#7: \n",
      "\n",
      "['says', 'brain', 'puerto', 'pregnancy', 'risk', 'dr', 'transmission', 'spread', 'vaccine', 'birth', 'cdc', 'babies', 'infected', 'brazil', 'outbreak', 'pregnant', 'microcephaly', 'cases', 'health', 'disease', 'mosquitoes', 'mosquito', 'women', 'virus', 'zika']\n",
      "\n",
      "The top 25 words for topic#8: \n",
      "\n",
      "['according', 'reported', 'violence', 'told', 'protesters', 'authorities', 'man', 'video', 'dallas', 'shot', 'department', 'enforcement', 'killed', 'city', 'gun', 'people', 'law', 'reports', 'attack', 'shooting', 'officer', 'black', 'said', 'officers', 'police']\n",
      "\n",
      "The top 25 words for topic#9: \n",
      "\n",
      "['case', 'democrats', 'white', 'judge', 'federal', 'obama', 'flynn', 'attorney', 'department', 'sessions', 'law', 'supreme', 'russian', 'russia', 'intelligence', 'said', 'investigation', 'committee', 'house', 'justice', 'president', 'senate', 'fbi', 'court', 'comey']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 25 words for topic#{index}: \")\n",
    "    print()\n",
    "    top25_words = [tfidf.get_feature_names()[j] for j in topic.argsort()[-25:]]\n",
    "    print(top25_words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a809b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 7 4 0]\n"
     ]
    }
   ],
   "source": [
    "# It attaches discovered topic labels to the original articles\n",
    "topic_results = nmf_model.transform(dtm)\n",
    "print(topic_results.argmax(axis=1))\n",
    "\n",
    "\n",
    "# assigning the index of the maximum value for each topic to the numerical topic label in the npr data frame.\n",
    "# creating a numerical topic label column called 'Topic' in the npr data frame.\n",
    "npr['Topic'] = topic_results.argmax(axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b064fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Topic\n",
       "0  In the Washington of 2016, even when the polic...      1\n",
       "1    Donald Trump has used Twitter  —   his prefe...      1\n",
       "2    Donald Trump is unabashedly praising Russian...      1\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
       "4  From photography, illustration and video, to d...      6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b159f57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Topic\n",
       "11987  The number of law enforcement officers shot an...      8\n",
       "11988    Trump is busy these days with victory tours,...      1\n",
       "11989  It’s always interesting for the Goats and Soda...      7\n",
       "11990  The election of Donald Trump was a surprise to...      4\n",
       "11991  Voters in the English city of Sunderland did s...      0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d1db0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Article  Topic\n",
      "0  In the Washington of 2016, even when the polic...      1\n",
      "1    Donald Trump has used Twitter  —   his prefe...      1\n",
      "2    Donald Trump is unabashedly praising Russian...      1\n",
      "3  Updated at 2:50 p. m. ET, Russian President Vl...      3\n",
      "4  From photography, illustration and video, to d...      6\n"
     ]
    }
   ],
   "source": [
    "print(npr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce7884f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Article  Topic\n",
      "11987  The number of law enforcement officers shot an...      8\n",
      "11988    Trump is busy these days with victory tours,...      1\n",
      "11989  It’s always interesting for the Goats and Soda...      7\n",
      "11990  The election of Donald Trump was a surprise to...      4\n",
      "11991  Voters in the English city of Sunderland did s...      0\n"
     ]
    }
   ],
   "source": [
    "print(npr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aae70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
