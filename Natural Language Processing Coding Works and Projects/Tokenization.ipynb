{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4573cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization in NLP\n",
    "# What is Tokenization?\n",
    "# Tokenization is the process of breaking up the original raw text into component pieces (tokens).\n",
    "# Tokens are the pieces of the original text.\n",
    "# Tokens are the basic building blocks of the document object. Everything that helps us to understand\n",
    "# the meaning of the text is derived from the tokens and their relationships to each other.\n",
    "\n",
    "# Prefix: Character(s) at the beginning (Examples: ?(\"$)\n",
    "# Suffix: Character(s) at the end (Examples: km ).!\")\n",
    "# Infix: Character(s) in between (Examples: /)\n",
    "# Exception: Special-case rule to split a string into several tokens or prevent a token from being\n",
    "# split when punctuation rules are applied. (Examples: let's U.S.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6527f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b247dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "# Escape character of \\ is used in the below string. \n",
    "# It is to not stop the whole string too early and escape the single quote in the string.\n",
    "my_string = '\"We\\'re moving to L.A.!\"'\n",
    "print(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2818fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "We\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# Spacy isolates punctuation that does not form an integral part of a word. One example to this kind of punctuation\n",
    "# is the question mark at the end of the sentence.\n",
    "document = nlp(my_string)\n",
    "for token in document: \n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5fb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snap\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "livesupport@site.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.site.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "second_string = \"We're here to help! Send snap-mail, email livesupport@site.com or visit us at http://www.site.com!\"\n",
    "second_document = nlp(second_string)\n",
    "for token in second_document:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bb8b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "Cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "11.10\n"
     ]
    }
   ],
   "source": [
    "# applying nlp pipeline of Spacy to the input text and retrieving a document object\n",
    "third_document = nlp(u\"A 5 km NYC Cab ride costs $11.10\") \n",
    "\n",
    "# iterating through whole document\n",
    "for token in third_document:\n",
    "    print(token.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "739499de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e15d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "token_num = len(doc4) # It gets the number of tokens in the document called doc4\n",
    "print(token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a85c74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x7f78b13214c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab objects contain a full library of items\n",
    "doc4.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e420318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.vocab.Vocab object at 0x7f78b13214c0>\n"
     ]
    }
   ],
   "source": [
    "print(doc4.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1962afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.vocab.Vocab'>\n",
      "803\n"
     ]
    }
   ],
   "source": [
    "print(type(doc4.vocab))\n",
    "print(len(doc4.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8227cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is better to give than receive.\n",
      "It\n",
      "is better to\n"
     ]
    }
   ],
   "source": [
    "fifth_document = nlp(u\"It is better to give than receive.\")\n",
    "print(fifth_document)\n",
    "print(fifth_document[0])\n",
    "print(fifth_document[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b90ab2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fifth_document[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "fifth_document[0] = \"test\" # It will throw a \"spacy.tokens.doc.Doc object does not support item assignment\" error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebd5cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | Inc. | has | built | a | factory | to | Tokyo | for | $ | 8 | million | dollars | . | "
     ]
    }
   ],
   "source": [
    "sixth_document = nlp(u\"Apple Inc. has built a factory to Tokyo for $8 million dollars.\")\n",
    "for token in sixth_document:\n",
    "    print(token.text, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c6eda85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. => ORG\n",
      "Tokyo => GPE\n",
      "$8 million dollars => MONEY\n"
     ]
    }
   ],
   "source": [
    "# Apple Inc., Tokyo, and $8 million dollars are the named entities \n",
    "# detected by Spacy in the given document called 'sixth_document'.\n",
    "\n",
    "# Displaying each entity and its label in all of the entities in the sixth document.t\n",
    "for entity in sixth_document.ents:\n",
    "    print(str(entity) + \" => \" + entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692dc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
