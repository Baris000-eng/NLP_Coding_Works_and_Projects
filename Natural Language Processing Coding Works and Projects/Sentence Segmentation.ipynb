{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac60e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x7fe4811bdd60>\n",
      "<class 'spacy.lang.en.English'>\n"
     ]
    }
   ],
   "source": [
    "# necessary imports \n",
    "import spacy\n",
    "\n",
    "# loading the small english core language library\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "print(nlp) \n",
    "print(type(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c300a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the initial sentence. This is another sentence. This is the last sentence.\n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "\n",
      "\n",
      "This is the initial sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "document = nlp(u\"This is the initial sentence. This is another sentence. This is the last sentence.\")\n",
    "print(document)\n",
    "print(type(document))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Displaying each sentence in the document\n",
    "for sentence in document.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f809a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1: This\n",
      "Word 2: is\n",
      "Word 3: the\n",
      "Word 4: initial\n",
      "Word 5: sentence\n",
      "Word 6: .\n",
      "Word 7: This\n",
      "Word 8: is\n",
      "Word 9: another\n",
      "Word 10: sentence\n",
      "Word 11: .\n",
      "Word 12: This\n",
      "Word 13: is\n",
      "Word 14: the\n",
      "Word 15: last\n",
      "Word 16: sentence\n",
      "Word 17: .\n"
     ]
    }
   ],
   "source": [
    "# Displaying each token in the document\n",
    "for i, token in enumerate(document):\n",
    "    print(\"Word \"+str(i+1)+\": \"+str(token)+\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5578fc34",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We cannot grab each sentence individually from doc.sents. Because it is a generator object and the generator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# objects are not subscriptable.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# We cannot grab each sentence individually from doc.sents. Because it is a generator object and the generator\n",
    "# objects are not subscriptable.\n",
    "document.sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770baba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(document.sents)) # gets the type of the generator object of document.sents\n",
    "print(list(document.sents))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# We should convert the document.sents to a list in order to make it subscriptable.\n",
    "for i in range(0, len(list(document.sents))):\n",
    "    print(\"Sentence \"+str(i+1)+\": \"+str(list(document.sents)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979021d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list(document.sents)[0])) # Span object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb285a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing things right; leadership is doing the right things.\" - Peter F. Drucker')\n",
    "print()\n",
    "print(doc)\n",
    "print(doc.text)\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fee910",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each token in the document doc, print that token and its index position\n",
    "for token in doc:\n",
    "    print(token, token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ways of adding new rules to the NLP pipeline:\n",
    "\n",
    "# 1-) Adding a segmentation rule\n",
    "# 2-) Change segmentation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_sentence_segmentation_rule\")\n",
    "def custom_sentence_segmentation_rule(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "# Add the custom sentence segmentation component to the pipeline\n",
    "#nlp.add_pipe(\"custom_sentence_segmentation_rule\", before=\"parser\")\n",
    "#nlp.remove_pipe(\"custom_sentence_segmentation\")\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "print(type(nlp.pipe_names)) # The list of pipe names is of type SimpleFrozenList.\n",
    "\n",
    "# SimpleFrozenList is a read-only list-like object in spaCy that is used to store pipeline component names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[:-1]) # Display all of the tokens up to but not including the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a45835",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" - Peter F. Drucker')\n",
    "print(doc5)\n",
    "print(type(doc5))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# As we can see from the output of this for loop, after adding a custom sentence segmentation rule of segmenting \n",
    "# the sentences based on the semicolon, the sentences in the output are splitted based on the semicolon.\n",
    "for sent in doc5.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371759b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24433b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e24adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf1333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "\n",
      "This is the third sentence.\n",
      "This is the \n",
      "fourth sentence.\n"
     ]
    }
   ],
   "source": [
    "#Â ALTER SENTENCE SEGMENTATION RULES\n",
    "nlp = spacy.load('en_core_web_sm') # reloading the english core language library\n",
    "myStr = u\"This is the first sentence.\\nThis is the second sentence.\\n\\nThis is the third sentence.\\nThis is the \\nfourth sentence.\"\n",
    "print(myStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e88dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "\n",
      "This is the third sentence.\n",
      "This is the \n",
      "fourth sentence.\n",
      "\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "custom_document = nlp(myStr)\n",
    "print(custom_document)\n",
    "print()\n",
    "print(type(custom_document)) # The document called 'custom_document' is a Doc object. It has a class of spacy.tokens.doc.Doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46221516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "\n",
      "This is the second sentence.\n",
      "\n",
      "\n",
      "This is the third sentence.\n",
      "\n",
      "This is the \n",
      "fourth sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in custom_document.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75f3dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "<class 'str'>\n",
      "fourth sentence.\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'g2']\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "from spacy.language import Language\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "@Language.component(\"split_on_newlines\") \n",
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    newLineEncountered = False\n",
    "    for word in doc:\n",
    "        if newLineEncountered:\n",
    "            start = word.i\n",
    "            newLineEncountered = False\n",
    "        elif word.text.startswith(\"\\n\"): # a new line has been encountered.\n",
    "            newLineEncountered = True\n",
    "            \n",
    "        \n",
    "    return doc[start:]\n",
    "\n",
    "nlp.add_pipe(\"split_on_newlines\")\n",
    "print(type(myStr))\n",
    "custom_doc = nlp(myStr)\n",
    "print(custom_doc)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39832c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fourth sentence."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_on_newlines(custom_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d324cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the \n",
      "fourth sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in custom_doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a42670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bbc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3755f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
