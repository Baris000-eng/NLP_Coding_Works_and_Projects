# -*- coding: utf-8 -*-
"""Chatbots.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dN6IAAihUlA2BEVrZx8hy9okFU6eMQrU
"""

# Implementation of a chatbot that can answer questions based on a 'story' given to the bot

# This project will use the BaBi dataset released by Facebook research.
# Link to the BaBi dataset: https://huggingface.co/datasets/facebook/babi_qa

# This dataset includes stories, questions, and answers.

# How QA Bot Network works ?

# * Model takes a discrete set of inputs x1, x2, x3, ....., xn that are to be stored in the
# memory, a query q, and outputs an answer a.

# * Each of the x, q, and a contains symbols coming from a dictionary with V words.

# * The model writes all x to the memory up to a fixed buffer size, and then finds a continuous
# representation for the x and q.

# Three Main Components of the End-To-End Network:
# 1-) Input Memory Representation: This shows how we actually take in the stories and questions.
# 2-) Output Memory Representation
# 3-) Generating Final Prediction

# Create a full model with RNN and Multiple Layers

# Input Memory Representation of Stories has the following formula:
# pi = softmax(u^T * mi)

# where softmax(zi) = e^(zi) / (j from 0 to k sum(e^(zj)))

# Output Memory Representation:
# * Each x input has a corresponding output vector c.

# Formula of Output Memory Representation:
# o = sum(pi * ci)

# Generating Final Prediction:

# In the single layer case, the sum of the output vector o and input embedding u is then passed
# through a final weight matrix W (of size V * d) and a softmax to predict the label.

# Probabilities of the predicted answer = Softmax(W(o+u))

# This network will produce a probability for every single word in the vocabulary.

# Mount Google Drive to '/content/drive'
from google.colab import drive
drive.mount('/content/drive')

pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive'

pwd

import numpy as np
import pickle

with open('train_qa.txt', 'rb') as train_file:
  train_data = pickle.load(train_file)

with open('test_qa.txt', 'rb') as test_file:
  test_data = pickle.load(test_file)

print('The train data for this Q&A Bot is: ')
print()
print(train_data)

print('------------------------------------------------------')
print()

print('The test data for this Q&A Bot is: ')
print()
print(test_data)
print()

print('------------------------------------------------------')
print()

print('The type of the train data is: '+str(type(train_data))+'')
print()
print('The type of the test data is: '+str(type(test_data))+'')

print('-----------------------------------------------------')

print('The length of train data is: '+str(len(train_data))+'')
print('The length of test data is: '+str(len(test_data))+'')
print('-----------------------------------------------------')

arr1 = [1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 2, 4, 4, 4, 4, 4, 4, 9 , 9 , 9 , 8 , 8 , 2, 2, 3, 3, 5, 7, 7]
arr2 = [2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 5, 5, 6, 3, 4, 5, 9, 9, 0, 1, 1, 1, 1, 5, 5, 7, 7, 9, 9, 11]

arr1 = set(arr1)
arr2 = set(arr2)

print(arr1.union(arr2))









