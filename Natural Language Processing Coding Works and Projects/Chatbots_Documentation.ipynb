{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnORccs3Qnoj"
      },
      "outputs": [],
      "source": [
        "# Implementation of a chatbot that can answer questions based on a 'story' given to the bot\n",
        "\n",
        "# This project will use the BaBi dataset released by Facebook research.\n",
        "# Link to the BaBi dataset: https://huggingface.co/datasets/facebook/babi_qa\n",
        "\n",
        "# This dataset includes stories, questions, and answers.\n",
        "\n",
        "# How QA Bot Network works ?\n",
        "\n",
        "# * Model takes a discrete set of inputs x1, x2, x3, ....., xn that are to be stored in the\n",
        "# memory, a query q, and outputs an answer a.\n",
        "\n",
        "# * Each of the x, q, and a contains symbols coming from a dictionary with V words.\n",
        "\n",
        "# * The model writes all x to the memory up to a fixed buffer size, and then finds a continuous\n",
        "# representation for the x and q.\n",
        "\n",
        "# Three Main Components of the End-To-End Network:\n",
        "# 1-) Input Memory Representation: This shows how we actually take in the stories and questions.\n",
        "# 2-) Output Memory Representation\n",
        "# 3-) Generating Final Prediction\n",
        "\n",
        "# Create a full model with RNN and Multiple Layers\n",
        "\n",
        "# Input Memory Representation of Stories has the following formula:\n",
        "# pi = softmax(u^T * mi)\n",
        "\n",
        "# where softmax(zi) = e^(zi) / (j from 0 to k sum(e^(zj)))\n",
        "\n",
        "# Output Memory Representation:\n",
        "# * Each x input has a corresponding output vector c.\n",
        "\n",
        "# Formula of Output Memory Representation:\n",
        "# o = sum(pi * ci)\n",
        "\n",
        "# Generating Final Prediction:\n",
        "\n",
        "# In the single layer case, the sum of the output vector o and input embedding u is then passed\n",
        "# through a final weight matrix W (of size V * d) and a softmax to predict the label.\n",
        "\n",
        "# Probabilities of the predicted answer = Softmax(W(o+u))\n",
        "\n",
        "# This network will produce a probability for every single word in the vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to '/content/drive'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVbrgkghZA7n",
        "outputId": "65e03ba3-b865-43c4-c006-3e76e3cbef81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JQMin0aLa-8x",
        "outputId": "7c1d738c-c268-4549-af15-dc18418ba598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ztDdiAcD2U",
        "outputId": "5d4b9609-3fe3-42d2-c35d-160da703d8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0qvcX-pLcD6N",
        "outputId": "fabfc21d-a394-45e5-b706-4497d88faee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "with open('train_qa.txt', 'rb') as train_file:\n",
        "  train_data = pickle.load(train_file)\n",
        "\n",
        "with open('test_qa.txt', 'rb') as test_file:\n",
        "  test_data = pickle.load(test_file)\n"
      ],
      "metadata": {
        "id": "6M46pikDXrBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The train data for this Q&A Bot is: ')\n",
        "print()\n",
        "print(train_data)\n",
        "\n",
        "print('------------------------------------------------------')\n",
        "print()\n",
        "\n",
        "print('The test data for this Q&A Bot is: ')\n",
        "print()\n",
        "print(test_data)\n",
        "print()\n",
        "\n",
        "print('------------------------------------------------------')\n",
        "print()\n",
        "\n",
        "print('The type of the train data is: '+str(type(train_data))+'')\n",
        "print()\n",
        "print('The type of the test data is: '+str(type(test_data))+'')\n",
        "\n",
        "print('-----------------------------------------------------')\n",
        "\n",
        "print('The length of train data is: '+str(len(train_data))+'')\n",
        "print('The length of test data is: '+str(len(test_data))+'')\n",
        "print('-----------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXrOGx5qXrIT",
        "outputId": "c5b42d3b-ed80-4808-c4e1-b068849c6b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = [1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 2, 4, 4, 4, 4, 4, 4, 9 , 9 , 9 , 8 , 8 , 2, 2, 3, 3, 5, 7, 7]\n",
        "arr2 = [2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 5, 5, 6, 3, 4, 5, 9, 9, 0, 1, 1, 1, 1, 5, 5, 7, 7, 9, 9, 11]\n",
        "\n",
        "arr1 = set(arr1)\n",
        "arr2 = set(arr2)\n",
        "\n",
        "print(arr1.union(arr2))"
      ],
      "metadata": {
        "id": "sbb26E38XrOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7d3e5e-2895-4bd4-e868-64857b6aff0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZRb1SnsLZNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jskOmLfXrW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWA1h3aEXran"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "db2iPs8fXrd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KRQlCoXXrho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}